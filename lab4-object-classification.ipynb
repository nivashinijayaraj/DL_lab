{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4607952,"sourceType":"datasetVersion","datasetId":2604803},{"sourceId":9107706,"sourceType":"datasetVersion","datasetId":5496691}],"dockerImageVersionId":30775,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"1","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.models import Model\nfrom keras.layers import Dense, Flatten\nfrom keras.preprocessing.image import ImageDataGeneratora\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\n\n# Load the dataset\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# Load the VGG16 model without the top fully connected layers\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n\n# Add custom layers on top of the base model\nx = Flatten()(base_model.output)\nx = Dense(256, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\n# Define the complete model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze the base model layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Preprocess the data\nx_train = preprocess_input(x_train)\nx_test = preprocess_input(x_test)\n\n# Create data generators for data augmentation\ndatagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\ndatagen.fit(x_train)\n\n# Train the model\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nmodel.fit(datagen.flow(x_train, y_train, batch_size=32), validation_data=(x_test, y_test), epochs=50, callbacks=[early_stopping])\n\n# Evaluate the model on test data\ntest_loss, test_accuracy = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**A] Basic object classification using pre-trained VGG16 Model**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.models import Model\nfrom keras.layers import Dense, Flatten\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\n\n# Load the dataset\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# Load the VGG16 model without the top fully connected layers\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n\n# Add custom layers on top of the base model\nx = Flatten()(base_model.output)\nx = Dense(256, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\n# Define the complete model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze the base model layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Preprocess the data\nx_train = preprocess_input(x_train)\nx_test = preprocess_input(x_test)\n\n# Create data generators for data augmentation\ndatagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\ndatagen.fit(x_train)\n\n# Train the model\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nmodel.fit(datagen.flow(x_train, y_train, batch_size=32), validation_data=(x_test, y_test), epochs=5, callbacks=[early_stopping])\n\n# Evaluate the model on test data\ntest_loss, test_accuracy = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T05:07:32.347820Z","iopub.execute_input":"2024-08-16T05:07:32.348833Z","iopub.status.idle":"2024-08-16T05:39:10.310519Z","shell.execute_reply.started":"2024-08-16T05:07:32.348786Z","shell.execute_reply":"2024-08-16T05:39:10.309303Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 238ms/step - accuracy: 0.4716 - loss: 3.2430 - val_accuracy: 0.6016 - val_loss: 1.1720\nEpoch 2/5\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 236ms/step - accuracy: 0.6010 - loss: 1.1403 - val_accuracy: 0.6388 - val_loss: 1.0698\nEpoch 3/5\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 237ms/step - accuracy: 0.6259 - loss: 1.0717 - val_accuracy: 0.6423 - val_loss: 1.0525\nEpoch 4/5\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 231ms/step - accuracy: 0.6407 - loss: 1.0310 - val_accuracy: 0.6449 - val_loss: 1.0692\nEpoch 5/5\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 232ms/step - accuracy: 0.6522 - loss: 0.9957 - val_accuracy: 0.6435 - val_loss: 1.0839\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 185ms/step - accuracy: 0.6393 - loss: 1.0701\nTest Accuracy: 64.23%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**b] ImageNet Classification with Deep residual Networks (RESNET)**","metadata":{}},{"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nimport numpy as np\n\n# Load the pre-trained ResNet50 model\nmodel = ResNet50(weights='imagenet')\n\n# Load an image file that contains an image to be classified\nimg_path = '/kaggle/input/rought-girl-dog-image/dogand girl image.jpg'  # Replace with the path to your image\nimg = image.load_img(img_path, target_size=(224, 224))\n\n# Convert the image to a numpy array\nx = image.img_to_array(img)\n\n# Add a batch dimension (since the model expects a batch of images)\nx = np.expand_dims(x, axis=0)\n\n# Preprocess the input image for the model\nx = preprocess_input(x)\n\n# Predict the class of the image\npredictions = model.predict(x)\n\n# Decode the top 3 predictions into human-readable class names\nprint('Predicted:', decode_predictions(predictions, top=3)[0])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T05:45:54.722328Z","iopub.execute_input":"2024-08-16T05:45:54.723494Z","iopub.status.idle":"2024-08-16T05:45:58.917519Z","shell.execute_reply.started":"2024-08-16T05:45:54.723407Z","shell.execute_reply":"2024-08-16T05:45:58.915560Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\nDownloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nPredicted: [('n02099849', 'Chesapeake_Bay_retriever', 0.1605571), ('n02109047', 'Great_Dane', 0.1506795), ('n02099267', 'flat-coated_retriever', 0.10858369)]\n","output_type":"stream"}]},{"cell_type":"code","source":"# both are same ","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:27:03.320000Z","iopub.execute_input":"2024-09-25T15:27:03.321482Z","iopub.status.idle":"2024-09-25T15:27:03.348500Z","shell.execute_reply.started":"2024-09-25T15:27:03.321404Z","shell.execute_reply":"2024-09-25T15:27:03.347172Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nimport numpy as np\n\n# Load the pre-trained ResNet50 model\nmodel = ResNet50(weights='imagenet')\n\n# Load an image file that contains an image to be classified\nimg_path = '/kaggle/input/rought-girl-dog-image/dogand girl image.jpg'  # Replace with your image path\nimg = image.load_img(img_path, target_size=(224, 224))\n\n# Convert the image to a numpy array\nx = image.img_to_array(img)\n\n# Add a batch dimension\nx = np.expand_dims(x, axis=0)\n\n# Preprocess the input image\nx = preprocess_input(x)\n\n# Predict the class of the image\npredictions = model.predict(x)\n\n# Decode and print the top 3 predicted classes with their probabilities\nprint('Predicted:', decode_predictions(predictions, top=3)[0])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T03:34:52.552042Z","iopub.execute_input":"2024-08-23T03:34:52.552558Z","iopub.status.idle":"2024-08-23T03:35:15.092167Z","shell.execute_reply.started":"2024-08-23T03:34:52.552521Z","shell.execute_reply":"2024-08-23T03:35:15.090952Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-23 03:34:55.173554: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-23 03:34:55.173777: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-23 03:34:55.359643: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\nDownloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nPredicted: [('n02099849', 'Chesapeake_Bay_retriever', 0.1605571), ('n02109047', 'Great_Dane', 0.1506795), ('n02099267', 'flat-coated_retriever', 0.10858369)]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense, Flatten\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping\n\n# Set up data directories\ntrain_dir = '/kaggle/input/flower-classification-5-classes-roselilyetc/Flower Classification/Flower Classification/Training Data'\nvalid_dir = '/kaggle/input/flower-classification-5-classes-roselilyetc/Flower Classification/Flower Classification/Testing Data'\n\n# Create data generators\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nvalid_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size=(224, 224),\n                                                    batch_size=32, class_mode='categorical')\nvalid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=(224, 224),\n                                                    batch_size=32, class_mode='categorical')\n\n# Load the pre-trained VGG16 model without the top fully connected layers\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers on top of the base model\nx = base_model.output\nx = Flatten()(x)\nx = Dense(256, activation='relu')(x)\npredictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n\n# Define the complete model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze the base model layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Set up early stopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Train the model\nmodel.fit(train_generator, epochs=5, validation_data=valid_generator, callbacks=[early_stopping])\n\n# Evaluate the model on validation data\nloss, accuracy = model.evaluate(valid_generator)\nprint(f'Validation Accuracy: {accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T03:43:42.426203Z","iopub.execute_input":"2024-08-23T03:43:42.426654Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Found 5000 images belonging to 5 classes.\nFound 958 images belonging to 5 classes.\nEpoch 1/5\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1714s\u001b[0m 11s/step - accuracy: 0.6493 - loss: 1.3760 - val_accuracy: 0.8006 - val_loss: 0.6285\nEpoch 2/5\n\u001b[1m 19/157\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:57\u001b[0m 9s/step - accuracy: 0.9222 - loss: 0.2260","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}